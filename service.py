# -*- coding: utf-8 -*-
"""service.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AUhAxoaqkYYwxHIPDg3kHNfdR4ijrrwB
"""

import os
import urllib.request

MODEL_PATH = "pet_breeds.pkl"
MODEL_URL = "https://drive.google.com/uc?export=download&id=1afSDn3rcmes_CsB5fl7rF9IMXgFER42N"

if not os.path.exists(MODEL_PATH):
    print("Downloading model...")
    urllib.request.urlretrieve(MODEL_URL, MODEL_PATH)
    print("Model downloaded.")

# service.py
from fastapi import FastAPI, UploadFile, File
from fastapi.responses import JSONResponse
from fastai.vision.all import load_learner, PILImage
import io

# Load model once at startup
# Make sure pet_breeds.pkl is in the same folder
learn = load_learner("pet_breeds.pkl")

app = FastAPI(
    title="Pet Breed Classifier API",
    description="Simple microservice exposing a pet breed image classifier",
    version="1.0.0",
)


@app.get("/")
def root():
    return {"status": "ok", "message": "Pet breed classifier is running"}


@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    # Basic validation
    if file.content_type.split("/")[0] != "image":
        return JSONResponse(
            status_code=400,
            content={"error": "Please upload an image file"},
        )

    # Read image bytes
    image_bytes = await file.read()

    # Convert to PIL image
    try:
        img = PILImage.create(io.BytesIO(image_bytes))
    except Exception as e:
        return JSONResponse(
            status_code=400,
            content={"error": f"Could not read image: {str(e)}"},
        )

    # Run prediction
    pred_class, pred_idx, probs = learn.predict(img)

    # Build response
    result = {
        "prediction": str(pred_class),
        "probability": float(probs[pred_idx]),
        "all_probabilities": {
            str(learn.dls.vocab[i]): float(probs[i]) for i in range(len(probs))
        },
    }

    return result